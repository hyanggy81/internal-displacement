

library(openxlsx)
library(caret)
library(glmnet)
library(ggplot2)
library(dplyr)


setwd("/Users/jiyoung/Desktop/M_thesis/Data/Final_Data")

# Read data
data <- read.xlsx("master_2009_2021_withoutNa3.xlsx")


# Preorocessing data

# Function to standardize a variable
standardize <- function(x) {
  return((x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))
}

# Standardize the positive independent variables
data <- data %>%
  group_by(iso3) %>%
  mutate(
    HDI_std = standardize(HDI),
    GDPpc_std = standardize(GDPpc),
    Urbanization_std = standardize(Urbanization),
    Vulnerability_std = standardize(Vulnerability),
    EconomicInequality_std = standardize(EconomicInequality),
    PublicServices_std = standardize(PublicServices),
    HumanRights_std = standardize(HumanRights),
    DemographicPressures_std = standardize(DemographicPressures)
  )


# Standardize the negative independent variables
log_transform <- function(x) {
  min_val <- min(x)
  if (min_val < 0) {
    # Add a constant value to make all values positive
    x <- x - min_val + 0.000001
  } else if (min_val == 0) {
    # Add a small positive value to prevent -Inf when taking logarithm
    x <- x + 0.000001
  }
  return(log(x))
}


# Log-transform variables with potential negative values
data <- data %>%
  mutate(
    GDPgrowth_log = log_transform(GDPgrowth),
    UrbanGrowth_log = log_transform(UrbanGrowth),
    PoliticalStability_log = log_transform(PoliticalStability),
    SPEI_log = log_transform(SPEI)
  )



# Function to standardize Conflict and Disasters variables (population's data)
standardize_cd <- function(x, pop) {
  return(log((x + 1) / (pop + 1)))
}

# Standardize Conflict and Disasters variables
data <- data %>%
  group_by(iso3) %>%
  mutate(
    Conflict_std = standardize_cd(Conflict, pop),
    Disasters_std = standardize_cd(Disasters, pop)
  )

# Log for depenant variables (Check: I need to add +1 to make positive value)
data <- data %>%
  group_by(iso3) %>%
  mutate(
    ID_conflict_log = log(ID_conflict + 1),
    ID_disasters_log = log(ID_disasters + 1), 
    IDPs_conflict_log = log(IDPs_conflict + 1),
    IDPs_disasters_log = log(IDPs_disasters + 1)
  )



summary(data)



# independent variables
independent_vars <- c(
  "HDI_std",
  "GDPpc_std",
  "Urbanization_std",
  "Vulnerability_std",
  "EconomicInequality_std",
  "PublicServices_std",
  "HumanRights_std",
  "DemographicPressures_std",
  "GDPgrowth_log",
  "UrbanGrowth_log",
  "PoliticalStability_log",
  "SPEI_log",
  "Conflict_std",
  "Disasters_std"
)



dependent_var1 <- "ID_conflict_log"
dependent_var2 <- "ID_disasters_log"
dependent_var3 <- "IDPs_conflict_log"
dependent_var4 <- "IDPs_disasters_log"


# Omit rows where any of the specified variables are NA
# Define the variables to check (independent and dependent variables)
variables_to_check <- c(independent_vars, "ID_conflict_log", "ID_disasters_log", "IDPs_conflict_log","IDPs_disasters_log" )

# Omit rows where any of the specified variables are NA
data <- data %>%
  filter(!if_any(all_of(variables_to_check), is.na))




################################## cross-validation



## Visualization for cross-validation
library(dplyr)
library(ggplot2)
library(tidyr)


years <- 2009:2021  # Defining the years explicitly
initialWindow <- 8
horizon <- 3
num_slices <- length(years) - initialWindow - horizon + 1

training_slices <- list()
testing_slices <- list()

# Generate the slices
for (i in 1:num_slices) {
  training_slices[[i]] <- years[i:(i + initialWindow - 1)]
  testing_slices[[i]] <- years[(i + initialWindow):(i + initialWindow + horizon - 1)]
}

# Prepare a dataframe for plotting
plot.df <- lapply(seq_along(training_slices), function(i) {
  train_df <- tibble(
    year = training_slices[[i]],
    spl.id = rep(i, length(training_slices[[i]])),
    spl.set = "Training"
  )
  
  test_df <- tibble(
    year = testing_slices[[i]],
    spl.id = rep(i, length(testing_slices[[i]])),
    spl.set = "Validation"
  )
  
  bind_rows(train_df, test_df)
}) %>%
  bind_rows() %>%
  mutate(year = as.factor(year))  

# Plotting the cross-validation scheme using ggplot2
ggplot(plot.df, aes(x = spl.id, y = year, fill = spl.set)) +
  geom_tile(color = "white") +
  scale_fill_viridis_d() +
  theme_bw() +
  theme(legend.title = element_blank()) +
  coord_flip() +
  xlab("Resample ID") + ylab("Year")

# Save the plot
ggsave("rollWindowScheme.jpeg", width = 10, height = 6)



################################################ model performance 

library(glmnet)
library(ggplot2)

# Initialize a dataframe to store model performance metrics
model_performances <- data.frame(Slice = integer(), RMSE = numeric(), Rsquared = numeric(), MAE = numeric())

# Loop through each slice for cross-validation
for (i in 1:length(training_slices)) {
  # Filter train and test sets for the current slice
  train_data <- filter(train.df, year %in% training_slices[[i]])
  test_data <- filter(train.df, year %in% testing_slices[[i]])
  
  # Check if Y_train has more than one unique value
  if(length(unique(train_data[[dependent_var1]])) <= 1) {
    cat("Slice", i, "skipped: Dependent variable is constant.\n")
    next  # Skip to the next iteration of the loop
  }
  
  # Prepare data for Elastic Net
  X_train <- as.matrix(train_data[, independent_vars])
  Y_train <- train_data[[dependent_var1]]
  X_test <- as.matrix(test_data[, independent_vars])
  Y_test <- test_data[[dependent_var1]]
  
  # Train the model using Elastic Net
  lambda_values <- seq(0, 1, 0.01)
  cv_model <- cv.glmnet(X_train, Y_train, type.measure = "mse", alpha = 0.5, family = "gaussian", lambda = lambda_values)
  
  # Select Optimal Lambda
  optimal_lambda <- cv_model$lambda.min
  
  # Predict on the testing set
  predictions <- predict(cv_model, newx = X_test, s = optimal_lambda)
  
  # Evaluate the model performance
  rmse <- sqrt(mean((predictions - Y_test)^2))
  rsquared <- 1 - sum((Y_test - predictions)^2) / sum((Y_test - mean(Y_test))^2)
  mae <- mean(abs(predictions - Y_test))
  
  # Store Performance for each slice
  model_performances <- rbind(model_performances, data.frame(Slice = i, RMSE = rmse, Rsquared = rsquared, MAE = mae))
}


# Output the results
print(model_performances)

# Assuming you want to analyze the model from the best performing slice
# Here, just selecting the first model as an example, replace with selection logic as needed
cv_model <- cv.glmnet(as.matrix(train.df[, independent_vars]), train.df[[dependent_var1]], type.measure = "mse", alpha = 0.5, family = "gaussian", lambda = seq(0, 1, 0.01))

# Extract the coefficients at the optimal value of lambda
optimal_coefs <- coef(cv_model, s = "lambda.min")

# Convert the sparse matrix into a regular numeric vector, excluding the intercept
coef_vector <- as.numeric(optimal_coefs[-1])

# Get the names of the coefficients (variables)
coef_names <- rownames(optimal_coefs)[-1]

# Create a data frame from the vectors
coef_df <- data.frame(Variable = coef_names, Coefficient = coef_vector)

# Remove zero coefficients if you only want to plot non-zero coefficients
coef_df <- coef_df[coef_df$Coefficient != 0, ]

# Order the data frame by the absolute value of the coefficients for plotting
coef_df <- coef_df[order(abs(coef_df$Coefficient), decreasing = TRUE), ]

# Plot the variable importance using ggplot2
ggplot(coef_df, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
  geom_bar(stat = "identity") +
  coord_flip() +  # Flip coordinates to make the plot horizontal
  theme_minimal() +
  labs(title = "Importance for Conflict-induced internal displacement", x = "Coefficient Value", y = "Variables")






####################### prediction test

# Predict on the testing set using the optimal lambda
predictions <- predict(cv_model, newx = X_test, s = optimal_lambda)


# Convert predictions 
predictions <- as.vector(predictions)

rmse_test <- sqrt(mean((predictions - Y_test)^2))
rsquared_test <- 1 - sum((Y_test - predictions)^2) / sum((Y_test - mean(Y_test))^2)
mae_test <- mean(abs(predictions - Y_test))

# Printing the evaluation metrics
cat("RMSE on Test Set:", rmse_test, "\n")
cat("R-squared on Test Set:", rsquared_test, "\n")
cat("MAE on Test Set:", mae_test, "\n")

# Assuming 'predictions' and 'Y_test' are available from the previous step
data_for_plot <- data.frame(Actual = Y_test, Predicted = predictions)

ggplot(data_for_plot, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.5) +  # Plot actual vs. predicted values
  geom_abline(color = "red", linetype = "dashed") +  # Line for perfect predictions
  labs(title = "Actual vs. Predicted Values", x = "Actual Values", y = "Predicted Values") +
  theme_minimal()

# Save the plot
ggsave("Actual_vs_Predicted.jpeg", width = 8, height = 6)



