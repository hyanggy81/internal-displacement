

library(openxlsx)
library(caret)
library(glmnet)
library(ggplot2)
library(dplyr)


setwd("/Users/jiyoung/Desktop/M_thesis/Data/Final_Data")

# Read data
data <- read.xlsx("master_2009_2021_withoutNa3.xlsx")


# Preorocessing data

# Function to standardize a variable
standardize <- function(x) {
  return((x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE))
}

# Standardize the positive independent variables
data <- data %>%
  group_by(iso3) %>%
  mutate(
    HDI_std = standardize(HDI),
    GDPpc_std = standardize(GDPpc),
    Urbanization_std = standardize(Urbanization),
    Vulnerability_std = standardize(Vulnerability),
    EconomicInequality_std = standardize(EconomicInequality),
    PublicServices_std = standardize(PublicServices),
    HumanRights_std = standardize(HumanRights),
    DemographicPressures_std = standardize(DemographicPressures),
    ExpectedSchooling_std =  standardize(ExpectedSchooling),	
    LifeExpectancy_std = standardize(LifeExpectancy)
    
  )


# Negative variables 
# Standardize the negative independent variables
log_transform <- function(x) {
  min_val <- min(x)
  if (min_val < 0) {
    # Add a constant value to make all values positive
    x <- x - min_val + 0.000001
  } else if (min_val == 0) {
    # Add a small positive value to prevent -Inf when taking logarithm
    x <- x + 0.000001
  }
  return(log(x))
}

# Log-transform variables with potential negative values
data <- data %>%
  mutate(
    GDPgrowth_log = log_transform(GDPgrowth),
    UrbanGrowth_log = log_transform(UrbanGrowth),
    PoliticalStability_log = log_transform(PoliticalStability),
    SPEI_log = log_transform(SPEI)
  )



# Function to standardize Conflict and Disasters variables (population's data)
standardize_cd <- function(x, pop) {
  return(log((x + 1) / (pop + 1)))
}

# Standardize Conflict and Disasters variables
data <- data %>%
  group_by(iso3) %>%
  mutate(
    Conflict_std = standardize_cd(Conflict, pop),
    Disasters_std = standardize_cd(Disasters, pop)
  )

# Log for depenant variables (Check: I need to add +1 to make positive value)
data <- data %>%
  group_by(iso3) %>%
  mutate(
    ID_conflict_log = log(ID_conflict + 1),
    ID_disasters_log = log(ID_disasters + 1), 
    IDPs_conflict_log = log(IDPs_conflict + 1),
    IDPs_disasters_log = log(IDPs_disasters + 1),
    ID_log = log(ID +1),
    IDPs_log =log(IDPs + 1)
  )



summary(data)



# independent variables
independent_vars <- c(
  "HDI_std",
  "GDPpc_std",
  "Urbanization_std",
  "Vulnerability_std",
  "GDPgrowth_log",
  "UrbanGrowth_log",
  "PoliticalStability_log",
  "SPEI_log",
  "Conflict_std",
  "Disasters_std"
  
)



dependent_var1 <- "ID_conflict_log"
dependent_var2 <- "ID_disasters_log"
dependent_var3 <- "IDPs_conflict_log"
dependent_var4 <- "IDPs_disasters_log"
dependent_var5 <- "ID_log"
dependent_var6 <- "IDPs_log"


# Omit rows where any of the specified variables are NA
# Define the variables to check (independent and dependent variables)
variables_to_check <- c(independent_vars, "ID_conflict_log", "ID_disasters_log", "IDPs_conflict_log","IDPs_disasters_log", "ID_log", "IDPs_log" )

# Omit rows where any of the specified variables are NA
data <- data %>%
  filter(!if_any(all_of(variables_to_check), is.na))




################################## cross-validation

library(dplyr)
library(ggplot2)
library(tidyr)

years <- 2009:2021 
initialWindow <- 8
horizon <- 3
num_slices <- length(years) - initialWindow - horizon + 1

# Initialize empty lists for training and testing slices
training_slices <- list()
testing_slices <- list()

# Generate the slices
for (i in 1:num_slices) {
  training_slices[[i]] <- years[i:(i + initialWindow - 1)]
  testing_slices[[i]] <- years[(i + initialWindow):(i + initialWindow + horizon - 1)]
}

# Prepare a dataframe for plotting
plot.df <- lapply(seq_along(training_slices), function(i) {
  train_df <- tibble(
    year = training_slices[[i]],
    spl.id = rep(i, length(training_slices[[i]])),
    spl.set = "Training"
  )
  
  test_df <- tibble(
    year = testing_slices[[i]],
    spl.id = rep(i, length(testing_slices[[i]])),
    spl.set = "Validation"
  )
  
  bind_rows(train_df, test_df)
}) %>%
  bind_rows() %>%
  mutate(year = as.factor(year))

# Plotting the cross-validation scheme using ggplot2
cross_val_plot <- ggplot(plot.df, aes(x = spl.id, y = year, fill = spl.set)) +
  geom_tile(color = "white") +
  scale_fill_viridis_d() +
  theme_bw() +
  theme(legend.title = element_blank()) +
  coord_flip() +
  xlab("Resample ID") + ylab("Year")

# Save the plot
ggsave("rollWindowScheme.jpeg", plot = cross_val_plot, width = 10, height = 6)

# Initialize a dataframe to store model performance metrics
model_performances <- data.frame(Slice = integer(), RMSE = numeric(), Rsquared = numeric(), MAE = numeric())

# Loop through each slice for cross-validation
for (i in 1:length(training_slices)) {
  # Filter train and test sets for the current slice
  train_data <- data %>%
    filter(year %in% training_slices[[i]])
  test_data <- data %>%
    filter(year %in% testing_slices[[i]])
  
  # Check if Y_train has more than one unique value
  if (length(unique(train_data[[dependent_var2]])) <= 1) {
    cat("Slice", i, "skipped: Dependent variable is constant.\n")
    next  # Skip to the next iteration of the loop
  }
  
  # Prepare data for Elastic Net
  X_train <- as.matrix(train_data[, independent_vars])
  Y_train <- train_data[[dependent_var2]]
  X_test <- as.matrix(test_data[, independent_vars])
  Y_test <- test_data[[dependent_var2]]
  
  
  # Split the data into training and testing sets
  set.seed(123)  # For reproducibility
  train_indices <- sample(1:nrow(data), 0.8 * nrow(data))  # 80% of data for training
  train.df <- data[train_indices, ]  # Training set
  test.df <- data[-train_indices, ]  # Testing set
  
  # Train the model using Elastic Net
  lambda_values <- seq(0, 1, 0.01)
  cv_model <- cv.glmnet(X_train, Y_train, type.measure = "mse", alpha = 0.5, family = "gaussian", lambda = lambda_values)
  
  # Select Optimal Lambda
  optimal_lambda <- cv_model$lambda.min
  
  # Predict on the testing set
  predictions <- predict(cv_model, newx = X_test, s = optimal_lambda)
  
  # Evaluate the model performance
  rmse <- sqrt(mean((predictions - Y_test)^2))
  rsquared <- 1 - sum((Y_test - predictions)^2) / sum((Y_test - mean(Y_test))^2)
  mae <- mean(abs(predictions - Y_test))
  
  # Store Performance for each slice
  model_performances <- rbind(model_performances, data.frame(Slice = i, RMSE = rmse, Rsquared = rsquared, MAE = mae))
}

# Output the results
print(model_performances)


# Extract the coefficients at the optimal value of lambda
optimal_lambda <- cv_model$lambda.min
optimal_coefs <- coef(cv_model, s = "lambda.min")

# Convert the sparse matrix into a regular numeric vector, excluding the intercept
coef_vector <- as.numeric(optimal_coefs[-1])

# Get the names of the coefficients (variables)
coef_names <- rownames(optimal_coefs)[-1]

# Create a data frame from the vectors
coef_df <- data.frame(Variable = coef_names, Coefficient = coef_vector)

# Remove zero coefficients if you only want to plot non-zero coefficients
coef_df <- coef_df[coef_df$Coefficient != 0, ]

# Order the data frame by the absolute value of the coefficients for plotting
coef_df <- coef_df[order(abs(coef_df$Coefficient), decreasing = TRUE), ]

# Plot the variable importance using ggplot2
ggplot(coef_df, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
  geom_bar(stat = "identity") +
  coord_flip() +  # Flip coordinates to make the plot horizontal
  theme_minimal() +
  labs(title = "Variable Importance", x = "Variables", y = "Coefficient Value")

